{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import google.generativeai as genai\n",
    "from streamlit import session_state as ss\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "\n",
    "# Loading embedings\n",
    "faiss_index = path + \"/faiss_index\"\n",
    "\n",
    "# Loading all the data files \n",
    "data_source = path + \"/data/data.txt\"\n",
    "pdf_source = path + \"/data/resume.pdf\"\n",
    "\n",
    "google_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "path = os.getcwd()\n",
    "pdf_path = path + \"/data/resume.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"Performs minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip() # note: this might be different for each doc (best to experiment)\n",
    "\n",
    "    # Other potential text formatting functions can go here\n",
    "    return cleaned_text\n",
    "\n",
    "def open_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    \n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    pages_and_text = []\n",
    "    for page_number, page in enumerate(pdf_document.pages()):\n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text)\n",
    "        pages_and_text.append({\"page_number\": page_number,  # adjust page numbers since our PDF starts on page 42\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "                                \"text\": text})\n",
    "    return pages_and_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_number': 26,\n",
       " 'page_char_count': 0,\n",
       " 'page_word_count': 1,\n",
       " 'page_sentence_count_raw': 1,\n",
       " 'page_token_count': 0.0,\n",
       " 'text': ''}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_text = open_read_pdf(pdf_path)\n",
    "# Remove the last page as it is empty\n",
    "pages_and_text.pop(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.50</td>\n",
       "      <td>2488.69</td>\n",
       "      <td>376.96</td>\n",
       "      <td>17.23</td>\n",
       "      <td>622.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.65</td>\n",
       "      <td>187.54</td>\n",
       "      <td>27.31</td>\n",
       "      <td>2.66</td>\n",
       "      <td>46.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1879.00</td>\n",
       "      <td>295.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>469.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.25</td>\n",
       "      <td>2439.25</td>\n",
       "      <td>365.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>609.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.50</td>\n",
       "      <td>2527.50</td>\n",
       "      <td>377.50</td>\n",
       "      <td>17.00</td>\n",
       "      <td>631.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.75</td>\n",
       "      <td>2579.75</td>\n",
       "      <td>394.00</td>\n",
       "      <td>18.75</td>\n",
       "      <td>644.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.00</td>\n",
       "      <td>2706.00</td>\n",
       "      <td>427.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>676.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        26.00            26.00            26.00                    26.00   \n",
       "mean         12.50          2488.69           376.96                    17.23   \n",
       "std           7.65           187.54            27.31                     2.66   \n",
       "min           0.00          1879.00           295.00                    12.00   \n",
       "25%           6.25          2439.25           365.00                    16.00   \n",
       "50%          12.50          2527.50           377.50                    17.00   \n",
       "75%          18.75          2579.75           394.00                    18.75   \n",
       "max          25.00          2706.00           427.00                    22.00   \n",
       "\n",
       "       page_token_count  \n",
       "count             26.00  \n",
       "mean             622.17  \n",
       "std               46.88  \n",
       "min              469.75  \n",
       "25%              609.81  \n",
       "50%              631.88  \n",
       "75%              644.94  \n",
       "max              676.50  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_text)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "for item in pages_and_text:\n",
    "    # Add sentences to each page\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "    # Make sure all sentences are strings\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "    # Count the sentences \n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.50</td>\n",
       "      <td>2488.69</td>\n",
       "      <td>376.96</td>\n",
       "      <td>17.23</td>\n",
       "      <td>622.17</td>\n",
       "      <td>18.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.65</td>\n",
       "      <td>187.54</td>\n",
       "      <td>27.31</td>\n",
       "      <td>2.66</td>\n",
       "      <td>46.88</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1879.00</td>\n",
       "      <td>295.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>469.75</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.25</td>\n",
       "      <td>2439.25</td>\n",
       "      <td>365.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>609.81</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.50</td>\n",
       "      <td>2527.50</td>\n",
       "      <td>377.50</td>\n",
       "      <td>17.00</td>\n",
       "      <td>631.88</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.75</td>\n",
       "      <td>2579.75</td>\n",
       "      <td>394.00</td>\n",
       "      <td>18.75</td>\n",
       "      <td>644.94</td>\n",
       "      <td>20.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.00</td>\n",
       "      <td>2706.00</td>\n",
       "      <td>427.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>676.50</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        26.00            26.00            26.00                    26.00   \n",
       "mean         12.50          2488.69           376.96                    17.23   \n",
       "std           7.65           187.54            27.31                     2.66   \n",
       "min           0.00          1879.00           295.00                    12.00   \n",
       "25%           6.25          2439.25           365.00                    16.00   \n",
       "50%          12.50          2527.50           377.50                    17.00   \n",
       "75%          18.75          2579.75           394.00                    18.75   \n",
       "max          25.00          2706.00           427.00                    22.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count             26.00                      26.00  \n",
       "mean             622.17                      18.65  \n",
       "std               46.88                       3.75  \n",
       "min              469.75                      13.00  \n",
       "25%              609.81                      16.00  \n",
       "50%              631.88                      17.50  \n",
       "75%              644.94                      20.75  \n",
       "max              676.50                      28.00  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_text)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 10 \n",
    "\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list: list, \n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
    "\n",
    "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in pages_and_text:\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.50</td>\n",
       "      <td>2488.69</td>\n",
       "      <td>376.96</td>\n",
       "      <td>17.23</td>\n",
       "      <td>622.17</td>\n",
       "      <td>18.65</td>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.65</td>\n",
       "      <td>187.54</td>\n",
       "      <td>27.31</td>\n",
       "      <td>2.66</td>\n",
       "      <td>46.88</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1879.00</td>\n",
       "      <td>295.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>469.75</td>\n",
       "      <td>13.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.25</td>\n",
       "      <td>2439.25</td>\n",
       "      <td>365.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>609.81</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.50</td>\n",
       "      <td>2527.50</td>\n",
       "      <td>377.50</td>\n",
       "      <td>17.00</td>\n",
       "      <td>631.88</td>\n",
       "      <td>17.50</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.75</td>\n",
       "      <td>2579.75</td>\n",
       "      <td>394.00</td>\n",
       "      <td>18.75</td>\n",
       "      <td>644.94</td>\n",
       "      <td>20.75</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.00</td>\n",
       "      <td>2706.00</td>\n",
       "      <td>427.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>676.50</td>\n",
       "      <td>28.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        26.00            26.00            26.00                    26.00   \n",
       "mean         12.50          2488.69           376.96                    17.23   \n",
       "std           7.65           187.54            27.31                     2.66   \n",
       "min           0.00          1879.00           295.00                    12.00   \n",
       "25%           6.25          2439.25           365.00                    16.00   \n",
       "50%          12.50          2527.50           377.50                    17.00   \n",
       "75%          18.75          2579.75           394.00                    18.75   \n",
       "max          25.00          2706.00           427.00                    22.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count             26.00                      26.00       26.00  \n",
       "mean             622.17                      18.65        2.27  \n",
       "std               46.88                       3.75        0.45  \n",
       "min              469.75                      13.00        2.00  \n",
       "25%              609.81                      16.00        2.00  \n",
       "50%              631.88                      17.50        2.00  \n",
       "75%              644.94                      20.75        2.75  \n",
       "max              676.50                      28.00        3.00  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_text)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in pages_and_text:\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo \n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# How many chunks do we have?\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 23,\n",
       "  'sentence_chunk': \"what project is Saurav most proud off?The project I am most proud of is the RAG pipeline I developed during my time as a Graduate Research Assistant. It involved integrating local LLMs with FAISS clustering to build a private AI service tailored to specific research needs. The complexity of the project, from deploying advanced AI techniques to managing vast datasets with PySpark and Apache Airflow, was incredibly challenging yet rewarding. It pushed my technical limits and gave me hands-on experience with cutting-edge technology. Currently, I am working on so many different projects that I could share with you soon!What is Saurav Mestry's passion?I am passionate about Software Development, Data Mining and Analytics, Machine Learning, and Conversational AI, but most of all, I am passionate about solving customers' problems using the technologies above. Tell me about Saurav's strengths | what about Saurav's strengths?My strengths lie in my analytical thinking and ability to solve complex problems efficiently.\",\n",
       "  'chunk_char_count': 1022,\n",
       "  'chunk_word_count': 155,\n",
       "  'chunk_token_count': 255.5},\n",
       " {'page_number': 5,\n",
       "  'sentence_chunk': \"This approach was necessary because traditional regression models struggled to capture the intricate interactions between temperature, voltage, and current, all of which influence the material’s phase transitions. The first crucial step in building the neural network was data preprocessing. The experimental data collected from tests on VO2 included various features like temperature, voltage, and current, all of which had different ranges. To ensure the model could efficiently learn from the data, I applied data normalization, scaling the input features so they were within a uniform range. This was essential to help the neural network avoid issues with uneven gradients and allowed for faster convergence during training. Additionally, I performed feature engineering, where I created interaction terms that represented the electro-thermal interplay more accurately. These new features helped the model account for the complex physics underlying the material's behavior. When designing the neural network, I opted for a feedforward architecture with multiple hidden layers. The input layer consisted of the scaled temperature, voltage, and current features. I included two hidden layers, each with ReLU (Rectified Linear Unit) activation functions.\",\n",
       "  'chunk_char_count': 1255,\n",
       "  'chunk_word_count': 178,\n",
       "  'chunk_token_count': 313.75},\n",
       " {'page_number': 10,\n",
       "  'sentence_chunk': 'By leveraging natural language processing (NLP) techniques, I was able to build models that classified comments as positive, negative, or neutral, giving us a clearer picture of audience reception and engagement. One of the highlights of the project was its ability to generate real-time insights. By building the pipeline on AWS, I ensured that the data processing was fast and efficient, allowing us to analyze incoming data in near real-time. This was particularly valuable for identifying trends as they emerged, such as detecting spikes in viewership or engagement related to viral content. The use of AWS Athena and Amazon QuickSight further allowed us to visualize these insights, creating dynamic dashboards that stakeholders could use to monitor key metrics without needing advanced technical knowledge. Throughout the project, I gained hands-on experience with cloud-native technologies and big data processing, learning how to manage data lakes, automate data pipelines, and',\n",
       "  'chunk_char_count': 985,\n",
       "  'chunk_word_count': 147,\n",
       "  'chunk_token_count': 246.25},\n",
       " {'page_number': 25,\n",
       "  'sentence_chunk': \"Can you provide more details about Saurav's degree in Management Information Systems?;Can you provide more details about Saurav Mestry's educational journey?I am currently pursuing my Master/'s in Management Information Systems at the University of Arizona with a focus on Business Intelligence. This program has allowed me to deepen my understanding of data-driven decision-making, data analytics, and how technology intersects with business. Some of the key courses I have taken include Database Design and Modeling, Big Data Technologies, and Product Management Essentials. It/\\x93s been a great blend of technical and strategic learning, and I/\\x93m maintaining a 4.0 GPA so far. Before that, I earned a dual degree (Bachelors-Masters) in Computer Science & Electrical Engineering from IIT Kanpur, which laid a strong foundation in data structures, machine learning, and software engineering. My time at IIT Kanpur was pivotal in shaping my technical skills, especially in fields like AI, data analytics, and software development. Balancing coursework and research there really prepared me for the challenges I face today, and it/\\x93s been an exciting journey from one learning experience to the next. What tools did Saurav use to build you?;\",\n",
       "  'chunk_char_count': 1238,\n",
       "  'chunk_word_count': 186,\n",
       "  'chunk_token_count': 309.5},\n",
       " {'page_number': 5,\n",
       "  'sentence_chunk': 'ReLU was chosen for its efficiency in modeling non-linear relationships and its ability to address the vanishing gradient problem, which can arise during backpropagation. This activation function enabled the network to learn complex patterns from the data, which was critical for predicting VO2’s phase transitions at different electro-thermal thresholds. The output layer used a linear activation function to predict the continuous variable representing the phase change of the material. To train the neural network, I used the mean squared error (MSE) as the loss function. MSE was ideal for this project because it provided a clear metric for evaluating the difference between the model’s predicted phase behavior and the actual experimental results. To optimize the model, I applied the Adam optimizer (Adaptive Moment Estimation), which is particularly effective for problems with noisy gradients. Adam allowed for efficient gradient-based optimization, speeding up the learning process and improving the model’s accuracy. Given the limited dataset, preventing overfitting was a significant concern. Overfitting occurs when a model becomes too complex and learns the noise in the training data, which reduces its ability to generalize to new data. To address this, I employed dropout regularization, where a random subset of neurons in the hidden layers was ignored during each training epoch.',\n",
       "  'chunk_char_count': 1398,\n",
       "  'chunk_word_count': 207,\n",
       "  'chunk_token_count': 349.5}]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(pages_and_chunks, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>59.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.68</td>\n",
       "      <td>1095.46</td>\n",
       "      <td>165.42</td>\n",
       "      <td>273.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.91</td>\n",
       "      <td>442.51</td>\n",
       "      <td>65.43</td>\n",
       "      <td>110.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>12.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.50</td>\n",
       "      <td>868.50</td>\n",
       "      <td>134.00</td>\n",
       "      <td>217.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.00</td>\n",
       "      <td>1111.00</td>\n",
       "      <td>166.00</td>\n",
       "      <td>277.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.00</td>\n",
       "      <td>1391.00</td>\n",
       "      <td>206.00</td>\n",
       "      <td>347.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.00</td>\n",
       "      <td>2041.00</td>\n",
       "      <td>311.00</td>\n",
       "      <td>510.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count        59.00             59.00             59.00              59.00\n",
       "mean         12.68           1095.46            165.42             273.86\n",
       "std           7.91            442.51             65.43             110.63\n",
       "min           0.00             51.00              9.00              12.75\n",
       "25%           5.50            868.50            134.00             217.12\n",
       "50%          13.00           1111.00            166.00             277.75\n",
       "75%          20.00           1391.00            206.00             347.75\n",
       "max          25.00           2041.00            311.00             510.25"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I belong to a humble middle class family. I wa...</td>\n",
       "      <td>931</td>\n",
       "      <td>166</td>\n",
       "      <td>232.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0            0  I belong to a humble middle class family. I wa...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \n",
       "0               931               166             232.75  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=content_data,\n",
    "    task_type=\"retrieval_document\",\n",
    "    title=\"profile\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in pages_and_chunks:\n",
    "    item[\"embedding\"] = genai.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        content=item[\"sentence_chunk\"],\n",
    "        task_type=\"retrieval_document\",\n",
    "        title=\"profile\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_number': 1,\n",
       " 'sentence_chunk': \"the systems and infrastructure that support our daily lives, while simultaneously establishing a solid, respectable career to support my family. Everyone has an epiphany in life that becomes a pivotal moment. When I was pursuing my undergraduate degree in Electrical and Computer Engineering, I had one such experience. The world craves innovative methods that can transform data into knowledge-rich treasure troves, bridging the gap between data and information. Today, in the era of technology-enhanced consumerism, every aspect of our everyday activities is captured in digital packets, which are subsequently analyzed and used to develop a company's marketing approach. Due to the growing connectedness and availability of technology, the quantity and variety of data collected by enterprises today are astounding. The issue with amassing a large volume of data is employing an efficient technique to access that data, regardless of the number of queries or the size of the data. In 2016, while anxiously awaiting the results of my JEE advanced entrance exam, I encountered this predicament. The examination is one of the most anticipated events on a national scale. As expected, a system failure caused by massive user requests prevented hundreds of hopefuls, including myself, from accessing their results for several hours.\",\n",
       " 'chunk_char_count': 1330,\n",
       " 'chunk_word_count': 202,\n",
       " 'chunk_token_count': 332.5,\n",
       " 'embedding': {'embedding': [0.025076663,\n",
       "   -0.056620877,\n",
       "   -0.045003872,\n",
       "   0.0052635437,\n",
       "   0.044637233,\n",
       "   0.055593114,\n",
       "   0.012396771,\n",
       "   -0.015339441,\n",
       "   -0.00017551245,\n",
       "   0.025046194,\n",
       "   0.01338402,\n",
       "   -0.019536262,\n",
       "   0.05541511,\n",
       "   0.007721598,\n",
       "   0.054355633,\n",
       "   -0.017043171,\n",
       "   0.021060731,\n",
       "   0.03185519,\n",
       "   -0.09088167,\n",
       "   -0.022702642,\n",
       "   0.015351095,\n",
       "   -0.024176192,\n",
       "   -0.030419828,\n",
       "   -0.028330505,\n",
       "   -0.0047226837,\n",
       "   0.025297828,\n",
       "   -0.0131650185,\n",
       "   -0.009975282,\n",
       "   -0.019000642,\n",
       "   0.018348547,\n",
       "   0.021143362,\n",
       "   0.02769174,\n",
       "   -0.02720713,\n",
       "   -0.018632904,\n",
       "   0.0049253996,\n",
       "   0.048682187,\n",
       "   -0.018919267,\n",
       "   -0.0029472504,\n",
       "   0.09784586,\n",
       "   -0.061140172,\n",
       "   -0.059422743,\n",
       "   0.0327897,\n",
       "   -0.08240078,\n",
       "   0.020254377,\n",
       "   -0.016134402,\n",
       "   -0.019807039,\n",
       "   -0.0020726316,\n",
       "   0.027202442,\n",
       "   -0.024823379,\n",
       "   0.065060094,\n",
       "   0.050956942,\n",
       "   -0.037524816,\n",
       "   -0.017883392,\n",
       "   0.05309929,\n",
       "   0.0020818375,\n",
       "   -0.013033201,\n",
       "   -0.012147551,\n",
       "   -0.03385312,\n",
       "   0.025786668,\n",
       "   -0.055253282,\n",
       "   0.009647013,\n",
       "   -0.029187812,\n",
       "   0.013092822,\n",
       "   -0.06576314,\n",
       "   0.030318758,\n",
       "   -0.023050215,\n",
       "   -0.021396114,\n",
       "   -0.030778773,\n",
       "   -0.07961052,\n",
       "   0.026908854,\n",
       "   -0.039400827,\n",
       "   0.050068133,\n",
       "   -0.033905543,\n",
       "   0.06788075,\n",
       "   0.021017088,\n",
       "   0.040039573,\n",
       "   0.020709563,\n",
       "   -0.028383315,\n",
       "   -0.0064524016,\n",
       "   0.039893527,\n",
       "   -0.0128449425,\n",
       "   0.042682253,\n",
       "   0.12048231,\n",
       "   0.025111267,\n",
       "   0.0033179934,\n",
       "   -0.053768963,\n",
       "   -0.0033720126,\n",
       "   -0.050116155,\n",
       "   -0.0063632126,\n",
       "   0.0059686415,\n",
       "   0.02603503,\n",
       "   0.04346237,\n",
       "   -0.0048773997,\n",
       "   0.01970292,\n",
       "   0.08023845,\n",
       "   -0.04362439,\n",
       "   -0.03404062,\n",
       "   -0.054579847,\n",
       "   0.114179954,\n",
       "   0.033799276,\n",
       "   0.0024590201,\n",
       "   0.011396572,\n",
       "   0.050205242,\n",
       "   -0.024521008,\n",
       "   0.024787007,\n",
       "   0.042398166,\n",
       "   -0.0046831868,\n",
       "   -0.030788202,\n",
       "   -0.019944131,\n",
       "   0.03835448,\n",
       "   -0.0558391,\n",
       "   0.028017292,\n",
       "   -0.03165086,\n",
       "   -0.04149221,\n",
       "   -0.0024491425,\n",
       "   0.0121841,\n",
       "   -0.021368338,\n",
       "   0.01576942,\n",
       "   -0.018766688,\n",
       "   0.06403,\n",
       "   -0.010927631,\n",
       "   0.006184268,\n",
       "   -0.07425765,\n",
       "   0.0848127,\n",
       "   0.010545994,\n",
       "   -0.03211846,\n",
       "   -0.011485573,\n",
       "   -0.0007773022,\n",
       "   -0.021406772,\n",
       "   -0.026149714,\n",
       "   0.058725357,\n",
       "   -0.05105856,\n",
       "   -0.020650474,\n",
       "   0.049415074,\n",
       "   -0.060701378,\n",
       "   -0.0074459543,\n",
       "   0.05613486,\n",
       "   -0.016619906,\n",
       "   0.038367752,\n",
       "   -0.0029595997,\n",
       "   0.024302255,\n",
       "   -0.029133327,\n",
       "   -0.07133457,\n",
       "   -0.007817699,\n",
       "   -0.03380507,\n",
       "   -0.055120178,\n",
       "   0.029716274,\n",
       "   0.08012516,\n",
       "   -0.0067225737,\n",
       "   0.023445118,\n",
       "   -0.03946489,\n",
       "   0.004245484,\n",
       "   0.040085334,\n",
       "   0.009275405,\n",
       "   -0.009392557,\n",
       "   -0.06394285,\n",
       "   0.07804474,\n",
       "   -0.03480197,\n",
       "   0.0340433,\n",
       "   0.02401109,\n",
       "   -0.02367983,\n",
       "   -0.03230028,\n",
       "   -0.0223847,\n",
       "   -0.021089513,\n",
       "   -0.051847782,\n",
       "   -0.03158108,\n",
       "   -0.009698625,\n",
       "   -0.029486874,\n",
       "   0.035011377,\n",
       "   0.037288673,\n",
       "   -0.012888892,\n",
       "   -0.0009446413,\n",
       "   -0.071338214,\n",
       "   -0.09586623,\n",
       "   0.012278341,\n",
       "   -0.0037107198,\n",
       "   -0.038308922,\n",
       "   -0.06947764,\n",
       "   -0.04429425,\n",
       "   0.0047770264,\n",
       "   0.06180331,\n",
       "   0.03332952,\n",
       "   -0.016710363,\n",
       "   -0.04534422,\n",
       "   0.009568872,\n",
       "   0.021160992,\n",
       "   -0.024980703,\n",
       "   0.09989218,\n",
       "   0.08680597,\n",
       "   0.06423565,\n",
       "   -0.0072209626,\n",
       "   -0.018089537,\n",
       "   -0.017651092,\n",
       "   -0.016311849,\n",
       "   -0.04924859,\n",
       "   -0.045992855,\n",
       "   -0.031419408,\n",
       "   -0.03779945,\n",
       "   -0.0008081444,\n",
       "   -0.06308142,\n",
       "   0.024522321,\n",
       "   -0.03824373,\n",
       "   0.005640684,\n",
       "   -0.046955373,\n",
       "   0.007582362,\n",
       "   0.024933944,\n",
       "   -0.044849668,\n",
       "   0.00042815116,\n",
       "   0.06518473,\n",
       "   0.017532406,\n",
       "   0.007955411,\n",
       "   -0.004402952,\n",
       "   -0.043625023,\n",
       "   -0.06997967,\n",
       "   0.020132374,\n",
       "   -0.0075494465,\n",
       "   0.06394295,\n",
       "   0.009754813,\n",
       "   0.13803108,\n",
       "   -0.008426575,\n",
       "   0.035347518,\n",
       "   -0.00058563345,\n",
       "   -0.030259697,\n",
       "   -0.010598744,\n",
       "   -0.00066522113,\n",
       "   0.061194554,\n",
       "   -0.039880108,\n",
       "   -0.054942034,\n",
       "   -0.017139886,\n",
       "   -0.06520915,\n",
       "   -0.010279854,\n",
       "   -0.006927163,\n",
       "   -0.0067085866,\n",
       "   0.018974613,\n",
       "   -0.025098896,\n",
       "   0.010028596,\n",
       "   0.05910167,\n",
       "   0.02186368,\n",
       "   0.004983635,\n",
       "   -0.03134483,\n",
       "   0.016457925,\n",
       "   0.008095081,\n",
       "   0.052836902,\n",
       "   0.009429809,\n",
       "   0.05930815,\n",
       "   0.03369,\n",
       "   0.029404648,\n",
       "   0.007639801,\n",
       "   0.012662795,\n",
       "   -0.06812357,\n",
       "   -0.030581398,\n",
       "   -0.017453572,\n",
       "   -0.023986934,\n",
       "   -0.021486172,\n",
       "   -0.065349,\n",
       "   -0.012894305,\n",
       "   -0.00080557895,\n",
       "   -0.046279505,\n",
       "   -0.0036908307,\n",
       "   -0.042593602,\n",
       "   0.07747415,\n",
       "   -0.041600622,\n",
       "   -0.033569615,\n",
       "   -0.07813415,\n",
       "   -0.013108293,\n",
       "   -0.07107717,\n",
       "   -0.04055071,\n",
       "   -0.0038126006,\n",
       "   0.022462487,\n",
       "   -0.035542153,\n",
       "   0.014475655,\n",
       "   -0.057472616,\n",
       "   -0.015525265,\n",
       "   -0.059231237,\n",
       "   -0.019448122,\n",
       "   0.058348123,\n",
       "   -0.0025031546,\n",
       "   0.0046525635,\n",
       "   0.007188595,\n",
       "   0.005783658,\n",
       "   -0.00032719126,\n",
       "   -0.018820297,\n",
       "   -0.02326077,\n",
       "   -0.012734426,\n",
       "   0.029899906,\n",
       "   -0.04631672,\n",
       "   -0.0010611643,\n",
       "   0.009816552,\n",
       "   -0.008292692,\n",
       "   -0.04197962,\n",
       "   0.05574753,\n",
       "   0.022966888,\n",
       "   -0.02041355,\n",
       "   -0.023027262,\n",
       "   0.03948488,\n",
       "   0.03220266,\n",
       "   0.024107251,\n",
       "   0.03777889,\n",
       "   0.02079594,\n",
       "   0.023666086,\n",
       "   0.043972638,\n",
       "   0.027199844,\n",
       "   -0.015878474,\n",
       "   -0.03742422,\n",
       "   0.023130028,\n",
       "   -0.0043444335,\n",
       "   0.010871395,\n",
       "   0.0168942,\n",
       "   -0.042721346,\n",
       "   0.05545831,\n",
       "   -0.004467653,\n",
       "   0.013782317,\n",
       "   -0.06918294,\n",
       "   -0.029337017,\n",
       "   -0.03424361,\n",
       "   -0.022049647,\n",
       "   -0.15416273,\n",
       "   -0.02350774,\n",
       "   -0.062101863,\n",
       "   0.025480505,\n",
       "   -0.0055045085,\n",
       "   0.05727042,\n",
       "   0.005278164,\n",
       "   0.017334059,\n",
       "   0.01264064,\n",
       "   0.008310523,\n",
       "   -0.004067585,\n",
       "   0.003962445,\n",
       "   0.045992363,\n",
       "   0.0062349243,\n",
       "   0.013525605,\n",
       "   -0.041865945,\n",
       "   0.04252697,\n",
       "   -0.044769287,\n",
       "   0.04978382,\n",
       "   0.026256487,\n",
       "   -0.024610642,\n",
       "   0.03556141,\n",
       "   0.07258043,\n",
       "   0.021203604,\n",
       "   -0.02200494,\n",
       "   0.033681806,\n",
       "   0.048420608,\n",
       "   0.009901317,\n",
       "   -0.0023939444,\n",
       "   -0.0075237434,\n",
       "   0.03948993,\n",
       "   -0.0106533365,\n",
       "   -0.003925615,\n",
       "   -0.0612398,\n",
       "   0.011382474,\n",
       "   -0.007288549,\n",
       "   0.045029063,\n",
       "   -0.021322552,\n",
       "   -0.04162668,\n",
       "   -0.0038628355,\n",
       "   0.0395468,\n",
       "   0.026271451,\n",
       "   -0.0015930518,\n",
       "   0.007994009,\n",
       "   -0.02951866,\n",
       "   0.020676749,\n",
       "   -0.02601123,\n",
       "   0.03618937,\n",
       "   -0.021456432,\n",
       "   0.030055886,\n",
       "   0.035399612,\n",
       "   -0.003932158,\n",
       "   -0.0032512448,\n",
       "   -0.0023384187,\n",
       "   -0.026983365,\n",
       "   0.032951113,\n",
       "   0.015344156,\n",
       "   -0.011673215,\n",
       "   0.055558983,\n",
       "   -0.015986316,\n",
       "   -0.013360851,\n",
       "   0.017703723,\n",
       "   0.03740146,\n",
       "   -0.012197589,\n",
       "   -0.011412756,\n",
       "   -0.07039108,\n",
       "   -0.014194429,\n",
       "   0.013424288,\n",
       "   -0.029807273,\n",
       "   0.08532936,\n",
       "   -0.087717526,\n",
       "   0.009206492,\n",
       "   0.04663921,\n",
       "   -0.0061919927,\n",
       "   0.022168994,\n",
       "   0.06724488,\n",
       "   -0.012426451,\n",
       "   0.0066487784,\n",
       "   -0.03353023,\n",
       "   0.0044193836,\n",
       "   -0.04558878,\n",
       "   0.016617049,\n",
       "   0.006991602,\n",
       "   0.04459265,\n",
       "   0.0078989025,\n",
       "   0.04699301,\n",
       "   0.08114916,\n",
       "   -0.0858335,\n",
       "   -0.029742558,\n",
       "   -0.006402331,\n",
       "   0.038383186,\n",
       "   0.0004240919,\n",
       "   0.0014810062,\n",
       "   -0.029282756,\n",
       "   0.015011569,\n",
       "   0.010617379,\n",
       "   -0.0067967116,\n",
       "   -0.00867147,\n",
       "   -0.001810316,\n",
       "   -0.03767184,\n",
       "   0.019448265,\n",
       "   -0.018507322,\n",
       "   -0.0016715652,\n",
       "   0.03677245,\n",
       "   0.0031690027,\n",
       "   0.007817041,\n",
       "   0.04519132,\n",
       "   -0.07204927,\n",
       "   0.015138645,\n",
       "   -0.031543933,\n",
       "   -0.004330132,\n",
       "   -0.026771393,\n",
       "   0.023481384,\n",
       "   0.05904688,\n",
       "   -0.008247871,\n",
       "   0.016525991,\n",
       "   -8.694394e-05,\n",
       "   -0.007799238,\n",
       "   0.00041835543,\n",
       "   0.022223277,\n",
       "   -0.036048345,\n",
       "   -0.021143105,\n",
       "   0.013234432,\n",
       "   0.002608688,\n",
       "   -0.025225459,\n",
       "   0.009223625,\n",
       "   0.0059701707,\n",
       "   0.024389422,\n",
       "   0.0072204294,\n",
       "   0.0274727,\n",
       "   0.05195376,\n",
       "   0.017135434,\n",
       "   -0.004829346,\n",
       "   0.01811212,\n",
       "   0.06491632,\n",
       "   -0.0038807814,\n",
       "   -0.013992221,\n",
       "   -0.013710965,\n",
       "   -0.050501086,\n",
       "   0.020525277,\n",
       "   -0.035514746,\n",
       "   -0.016173154,\n",
       "   -0.02728097,\n",
       "   -0.02430956,\n",
       "   -0.010951997,\n",
       "   -0.021248685,\n",
       "   0.07260061,\n",
       "   0.063392244,\n",
       "   0.012605891,\n",
       "   -0.0058119358,\n",
       "   0.031248247,\n",
       "   0.06925174,\n",
       "   -0.052703954,\n",
       "   0.029179156,\n",
       "   0.03549945,\n",
       "   0.02270185,\n",
       "   -0.014588746,\n",
       "   0.00978602,\n",
       "   -0.06360268,\n",
       "   -0.00487989,\n",
       "   0.038767457,\n",
       "   0.019174755,\n",
       "   -0.026695186,\n",
       "   -0.041406132,\n",
       "   -0.011210409,\n",
       "   0.023038505,\n",
       "   -0.030957138,\n",
       "   0.024923522,\n",
       "   0.034936916,\n",
       "   0.010771301,\n",
       "   -0.030593751,\n",
       "   -0.028618619,\n",
       "   -0.003919964,\n",
       "   0.011934106,\n",
       "   0.037003834,\n",
       "   0.017176671,\n",
       "   -0.008693219,\n",
       "   0.0031598008,\n",
       "   -0.021995574,\n",
       "   -0.012531423,\n",
       "   0.06373926,\n",
       "   0.03291946,\n",
       "   -0.017831173,\n",
       "   0.014300718,\n",
       "   0.07823374,\n",
       "   0.012710861,\n",
       "   -0.0007869825,\n",
       "   -0.0066887294,\n",
       "   -0.04873028,\n",
       "   0.0018047254,\n",
       "   -0.03851311,\n",
       "   0.01756108,\n",
       "   0.055315144,\n",
       "   0.034181017,\n",
       "   0.04287194,\n",
       "   0.021907337,\n",
       "   0.024364278,\n",
       "   -0.010253126,\n",
       "   -0.026966266,\n",
       "   0.0062426683,\n",
       "   -0.026228994,\n",
       "   0.023603166,\n",
       "   -0.027128369,\n",
       "   -0.01033148,\n",
       "   0.007613319,\n",
       "   -0.01449314,\n",
       "   0.03927611,\n",
       "   0.0006691332,\n",
       "   -0.0032919438,\n",
       "   -0.069456846,\n",
       "   -0.025141079,\n",
       "   0.027349941,\n",
       "   0.0112623125,\n",
       "   -0.040683124,\n",
       "   0.03561632,\n",
       "   0.06259279,\n",
       "   0.07036553,\n",
       "   -0.025507981,\n",
       "   0.019429753,\n",
       "   0.066939585,\n",
       "   -0.015450403,\n",
       "   0.039216757,\n",
       "   0.016124751,\n",
       "   0.04414868,\n",
       "   -0.008261832,\n",
       "   0.019770594,\n",
       "   0.01417085,\n",
       "   0.0090678,\n",
       "   0.031540424,\n",
       "   -0.030313326,\n",
       "   -0.033689097,\n",
       "   0.04985083,\n",
       "   0.01224072,\n",
       "   0.08672711,\n",
       "   -0.029495068,\n",
       "   -0.022315746,\n",
       "   0.0137169305,\n",
       "   0.0008151556,\n",
       "   0.005087661,\n",
       "   0.004469587,\n",
       "   -0.0025064514,\n",
       "   0.041421577,\n",
       "   -0.035670377,\n",
       "   -0.04122576,\n",
       "   -0.02423253,\n",
       "   -0.023726907,\n",
       "   0.0009769336,\n",
       "   0.016238252,\n",
       "   -0.03396632,\n",
       "   0.038149748,\n",
       "   -0.0102200955,\n",
       "   0.020445673,\n",
       "   -0.01554608,\n",
       "   -0.03288978,\n",
       "   0.03725232,\n",
       "   -0.018046621,\n",
       "   0.04116266,\n",
       "   -0.042150438,\n",
       "   -0.0011238966,\n",
       "   0.010708762,\n",
       "   -0.037995238,\n",
       "   -0.0061093243,\n",
       "   0.01587742,\n",
       "   0.007390227,\n",
       "   0.014287036,\n",
       "   -0.0055293175,\n",
       "   0.048440274,\n",
       "   0.030720947,\n",
       "   0.012959543,\n",
       "   0.0037134625,\n",
       "   0.014804673,\n",
       "   0.047337823,\n",
       "   0.019266974,\n",
       "   -0.054565985,\n",
       "   0.00766249,\n",
       "   0.032264795,\n",
       "   0.08362862,\n",
       "   -0.053465657,\n",
       "   0.05926118,\n",
       "   0.00060424453,\n",
       "   -0.03567792,\n",
       "   0.019707931,\n",
       "   -0.011299066,\n",
       "   0.0063990722,\n",
       "   0.0010558495,\n",
       "   -0.020103937,\n",
       "   0.09679731,\n",
       "   -0.038837012,\n",
       "   0.004429186,\n",
       "   -0.030541906,\n",
       "   -0.010978807,\n",
       "   -0.038668137,\n",
       "   -0.00075501535,\n",
       "   -0.06575819,\n",
       "   0.065584846,\n",
       "   0.02120374,\n",
       "   -0.031412486,\n",
       "   0.019109476,\n",
       "   -0.10597748,\n",
       "   -0.015559898,\n",
       "   -0.03629154,\n",
       "   0.014830947,\n",
       "   -0.025198618,\n",
       "   0.0064782435,\n",
       "   0.02827802,\n",
       "   0.06473661,\n",
       "   0.026071222,\n",
       "   0.0033274293,\n",
       "   -0.01569343,\n",
       "   0.05341804,\n",
       "   0.0013964432,\n",
       "   -0.0028137162,\n",
       "   0.07357839,\n",
       "   -0.02595497,\n",
       "   0.005755401,\n",
       "   0.0021029308,\n",
       "   0.026531206,\n",
       "   -0.05703217,\n",
       "   0.005590541,\n",
       "   -0.015698973,\n",
       "   0.0056952783,\n",
       "   -0.029557386,\n",
       "   0.039617818,\n",
       "   -0.050975647,\n",
       "   -0.018650386,\n",
       "   0.03151822,\n",
       "   0.014565817,\n",
       "   0.008001169,\n",
       "   0.0024729867,\n",
       "   0.01281542,\n",
       "   -0.0074156174,\n",
       "   0.0038575102,\n",
       "   0.03560961,\n",
       "   0.021435997,\n",
       "   0.020604223,\n",
       "   0.065396994,\n",
       "   -0.057995226,\n",
       "   0.028445896,\n",
       "   -0.00849952,\n",
       "   0.009883094,\n",
       "   -0.022385808,\n",
       "   -0.0041050473,\n",
       "   0.0027874678,\n",
       "   0.0041136076,\n",
       "   0.039468884,\n",
       "   -0.027834184,\n",
       "   0.008153409,\n",
       "   0.029796306,\n",
       "   -0.01318361,\n",
       "   0.0120008765,\n",
       "   0.0045286505,\n",
       "   0.024532922,\n",
       "   0.008878556,\n",
       "   0.018991016,\n",
       "   0.008190788,\n",
       "   -0.027250785,\n",
       "   -0.03609467,\n",
       "   0.047021266,\n",
       "   -0.0020562324,\n",
       "   0.018975932,\n",
       "   0.05190956,\n",
       "   -0.051578995,\n",
       "   -0.023686487,\n",
       "   0.0006143172,\n",
       "   0.030384557,\n",
       "   -0.032737408,\n",
       "   -0.01812531,\n",
       "   0.013325415,\n",
       "   0.06479848,\n",
       "   0.04036881,\n",
       "   0.053729657,\n",
       "   -0.043496236,\n",
       "   0.011459031,\n",
       "   0.006592436,\n",
       "   0.0048404825,\n",
       "   -0.03801162,\n",
       "   -0.026385017,\n",
       "   0.014716672,\n",
       "   0.0029412317,\n",
       "   0.06874839,\n",
       "   -0.009332099,\n",
       "   0.064636536,\n",
       "   -0.020373061,\n",
       "   0.008284847,\n",
       "   -0.01436583,\n",
       "   0.020176621,\n",
       "   -0.053964365,\n",
       "   -0.033921227,\n",
       "   -0.01598523,\n",
       "   0.019971604,\n",
       "   0.011165117,\n",
       "   0.013012585,\n",
       "   -0.023321649,\n",
       "   -0.016850548,\n",
       "   -0.036227148,\n",
       "   -0.025936259,\n",
       "   0.0413622,\n",
       "   0.011198739,\n",
       "   -0.025924966,\n",
       "   -0.0049606776,\n",
       "   0.024218548,\n",
       "   0.042706035,\n",
       "   0.023319589,\n",
       "   -0.0065344074,\n",
       "   0.03831808,\n",
       "   -0.053155996,\n",
       "   0.07735432,\n",
       "   0.06998726,\n",
       "   -0.006683462,\n",
       "   0.0047022514,\n",
       "   -0.06566401,\n",
       "   -0.017461037,\n",
       "   -0.0172458,\n",
       "   0.032636218,\n",
       "   -0.004208218,\n",
       "   0.015138072,\n",
       "   -0.0100972755,\n",
       "   0.07355269,\n",
       "   -0.05787468,\n",
       "   -0.0141960615,\n",
       "   -0.0328818,\n",
       "   0.011912415,\n",
       "   -0.013814619,\n",
       "   -0.036459584,\n",
       "   -0.009401989,\n",
       "   -0.006160768,\n",
       "   -0.033495404,\n",
       "   -0.043371964,\n",
       "   -0.03676854,\n",
       "   0.007381321,\n",
       "   -0.0018610327,\n",
       "   0.0005281473,\n",
       "   -0.0020391813,\n",
       "   -0.028460732,\n",
       "   -0.04635795,\n",
       "   -0.04173981,\n",
       "   0.048324004,\n",
       "   -0.0020695413,\n",
       "   0.026417824,\n",
       "   0.014168545,\n",
       "   0.030723788,\n",
       "   -0.02952166,\n",
       "   -0.0004011639,\n",
       "   0.029964177,\n",
       "   -0.07611413,\n",
       "   0.053616248,\n",
       "   -0.03332035,\n",
       "   -0.015431389,\n",
       "   -0.06279328,\n",
       "   0.00083897595,\n",
       "   0.002094917,\n",
       "   -0.0063880407]}}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now store 'page_number', 'sentence_chunk', 'chunk_word_count', 'chunk_token_count', 'embedding'['embedding'] into new dictionary\n",
    "\n",
    "embeddings = []\n",
    "for item in pages_and_chunks:\n",
    "    embeddings.append({\n",
    "        \"page_number\": item[\"page_number\"],\n",
    "        \"sentence_chunk\": item[\"sentence_chunk\"],\n",
    "        \"chunk_word_count\": item[\"chunk_word_count\"],\n",
    "        \"chunk_token_count\": item[\"chunk_token_count\"],\n",
    "        \"embedding\": item[\"embedding\"][\"embedding\"]\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store pages_and_chunks into a json file\n",
    "with open('data/embeddings.json', 'w') as f:\n",
    "    json.dump(embeddings, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the embeddings to a DataFrame\n",
    "df = pd.DataFrame(embeddings)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pages_and_chunks as a dictionary\n",
    "with open('data/pages_and_chunks.json', 'w') as f:\n",
    "    json.dump(pages_and_chunks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file for later use\n",
    "df.to_csv(\"data/embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I belong to a humble middle class family. I wa...</td>\n",
       "      <td>166</td>\n",
       "      <td>232.75</td>\n",
       "      <td>[-0.00085764396, -0.026951997, -0.102263525, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I am open to relocation at my own expense. The...</td>\n",
       "      <td>230</td>\n",
       "      <td>368.25</td>\n",
       "      <td>[-0.0039868755, -0.01167271, -0.087820984, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>In light of these considerations, I deemed it ...</td>\n",
       "      <td>16</td>\n",
       "      <td>24.50</td>\n",
       "      <td>[0.017440695, -0.025678309, -0.07075134, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>the systems and infrastructure that support ou...</td>\n",
       "      <td>202</td>\n",
       "      <td>332.50</td>\n",
       "      <td>[0.025076663, -0.056620877, -0.045003872, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This experience made me understand that it is ...</td>\n",
       "      <td>193</td>\n",
       "      <td>312.50</td>\n",
       "      <td>[-0.0050783064, -0.016273735, -0.060798004, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>information systems from your highly regarded ...</td>\n",
       "      <td>208</td>\n",
       "      <td>335.75</td>\n",
       "      <td>[0.029690873, -0.044833057, -0.07459464, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>The project revolved around customer behavior ...</td>\n",
       "      <td>151</td>\n",
       "      <td>277.75</td>\n",
       "      <td>[-0.027738323, -0.053028014, -0.04565362, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>accordingly. I used Python’s NLTK and TextBlob...</td>\n",
       "      <td>179</td>\n",
       "      <td>320.50</td>\n",
       "      <td>[-0.008610588, -0.04613524, -0.059771553, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Finding the desired signal in the dataset was ...</td>\n",
       "      <td>155</td>\n",
       "      <td>239.00</td>\n",
       "      <td>[-0.005382348, -0.023848232, -0.059643026, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Aside from that, I was actively involved in or...</td>\n",
       "      <td>23</td>\n",
       "      <td>35.75</td>\n",
       "      <td>[0.010427879, -0.036940105, -0.009767175, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>festival, I used aggressive pricing and market...</td>\n",
       "      <td>286</td>\n",
       "      <td>475.75</td>\n",
       "      <td>[0.007850425, -0.04826677, -0.07483711, 0.0124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>I employed machine learning algorithms, includ...</td>\n",
       "      <td>79</td>\n",
       "      <td>152.50</td>\n",
       "      <td>[-0.017504912, -0.0077653434, -0.07827265, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>This approach was necessary because traditiona...</td>\n",
       "      <td>178</td>\n",
       "      <td>313.75</td>\n",
       "      <td>[-0.03823464, -0.04391566, -0.08481946, 0.0229...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>ReLU was chosen for its efficiency in modeling...</td>\n",
       "      <td>207</td>\n",
       "      <td>349.50</td>\n",
       "      <td>[0.00096199644, -0.0356134, -0.06615024, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>This forced the neural network to learn more r...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.75</td>\n",
       "      <td>[0.020866314, -0.04303474, -0.08289091, 0.0420...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>patterns in the data, rather than memorizing s...</td>\n",
       "      <td>191</td>\n",
       "      <td>332.25</td>\n",
       "      <td>[-0.039007228, -0.04380813, -0.056690536, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>By applying these neural network techniques, I...</td>\n",
       "      <td>173</td>\n",
       "      <td>309.00</td>\n",
       "      <td>[-0.04947887, -0.03431822, -0.0737662, 0.02064...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>hardware research and software engineering, ma...</td>\n",
       "      <td>274</td>\n",
       "      <td>468.25</td>\n",
       "      <td>[-0.0068085454, -0.01160138, -0.066400416, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>The architecture followed the principles of mo...</td>\n",
       "      <td>91</td>\n",
       "      <td>160.25</td>\n",
       "      <td>[-0.02829502, -0.04092605, -0.039455872, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>between internal services and external clients...</td>\n",
       "      <td>190</td>\n",
       "      <td>325.75</td>\n",
       "      <td>[0.010099944, -0.03889013, -0.052069496, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>This aspect of my role was incredibly rewardin...</td>\n",
       "      <td>191</td>\n",
       "      <td>318.00</td>\n",
       "      <td>[0.0053883996, -0.034744136, -0.05569161, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>laid a strong foundation for my career as a so...</td>\n",
       "      <td>248</td>\n",
       "      <td>371.50</td>\n",
       "      <td>[0.021201478, -0.020574233, -0.06713662, 0.012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>This project required a deep understanding of ...</td>\n",
       "      <td>179</td>\n",
       "      <td>285.25</td>\n",
       "      <td>[-0.0403763, -0.044990357, -0.06994495, -0.002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>was ingested, I used AWS Glue to transform the...</td>\n",
       "      <td>247</td>\n",
       "      <td>426.50</td>\n",
       "      <td>[-0.047331795, -0.055383295, -0.073855855, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>By leveraging natural language processing (NLP...</td>\n",
       "      <td>147</td>\n",
       "      <td>246.25</td>\n",
       "      <td>[-0.05849922, -0.05775203, -0.06674202, 0.0081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11</td>\n",
       "      <td>implement machine learning algorithms for patt...</td>\n",
       "      <td>247</td>\n",
       "      <td>415.00</td>\n",
       "      <td>[-0.013706977, -0.030732168, -0.07182885, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11</td>\n",
       "      <td>Once the conceptual model was approved, I move...</td>\n",
       "      <td>134</td>\n",
       "      <td>217.25</td>\n",
       "      <td>[-0.022853032, -0.026697159, -0.05576489, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12</td>\n",
       "      <td>tasks, such as updating records, ensuring refe...</td>\n",
       "      <td>234</td>\n",
       "      <td>384.25</td>\n",
       "      <td>[-0.010861761, -0.031268716, -0.037806783, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12</td>\n",
       "      <td>This also enhanced the reliability of the syst...</td>\n",
       "      <td>162</td>\n",
       "      <td>271.75</td>\n",
       "      <td>[-0.0022070908, -0.023297058, -0.06229443, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13</td>\n",
       "      <td>estate property management company, Cortland L...</td>\n",
       "      <td>244</td>\n",
       "      <td>403.25</td>\n",
       "      <td>[-0.0045884596, -0.037297305, -0.021144431, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>13</td>\n",
       "      <td>By building asynchronous, non-blocking APIs, I...</td>\n",
       "      <td>155</td>\n",
       "      <td>263.25</td>\n",
       "      <td>[-0.0039411876, -0.037921496, -0.070832245, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>14</td>\n",
       "      <td>using GitHub Actions. This automated the testi...</td>\n",
       "      <td>231</td>\n",
       "      <td>392.75</td>\n",
       "      <td>[0.005633869, -0.035317738, -0.044113375, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14</td>\n",
       "      <td>During my academic journey at University of Ar...</td>\n",
       "      <td>147</td>\n",
       "      <td>237.50</td>\n",
       "      <td>[-0.01571211, -0.0138244, -0.08292807, 0.01997...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15</td>\n",
       "      <td>retrieval mechanism to provide more contextual...</td>\n",
       "      <td>224</td>\n",
       "      <td>395.50</td>\n",
       "      <td>[-0.025009813, -0.04231282, -0.089524455, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15</td>\n",
       "      <td>This migration not only improved the reliabili...</td>\n",
       "      <td>150</td>\n",
       "      <td>274.25</td>\n",
       "      <td>[0.00019663524, -0.048781164, -0.0800414, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>systems I developed were not only scalable but...</td>\n",
       "      <td>311</td>\n",
       "      <td>510.25</td>\n",
       "      <td>[-0.002703922, -0.025814788, -0.07945316, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16</td>\n",
       "      <td>Our college did not just limit us to technical...</td>\n",
       "      <td>79</td>\n",
       "      <td>128.50</td>\n",
       "      <td>[0.0032396496, -0.01736006, -0.06494775, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>17</td>\n",
       "      <td>through developing AI-driven solutions, design...</td>\n",
       "      <td>243</td>\n",
       "      <td>407.50</td>\n",
       "      <td>[-0.02889661, -0.02963389, -0.05241359, -0.018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>17</td>\n",
       "      <td>As much as I love the rapid pace of technologi...</td>\n",
       "      <td>134</td>\n",
       "      <td>223.50</td>\n",
       "      <td>[-0.023759237, -0.023016144, -0.076971054, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>18</td>\n",
       "      <td>each student, regardless of where they come fr...</td>\n",
       "      <td>219</td>\n",
       "      <td>356.00</td>\n",
       "      <td>[-0.0014291801, -0.015417845, -0.037049927, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>18</td>\n",
       "      <td>I want to be at the forefront of efforts that ...</td>\n",
       "      <td>189</td>\n",
       "      <td>278.75</td>\n",
       "      <td>[0.013005755, -0.022814292, -0.045691047, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>19</td>\n",
       "      <td>what is his educational background| tell me ab...</td>\n",
       "      <td>205</td>\n",
       "      <td>346.50</td>\n",
       "      <td>[-0.022183333, -0.026611745, -0.09239627, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>19</td>\n",
       "      <td>To name a few certificates - I have an Databas...</td>\n",
       "      <td>111</td>\n",
       "      <td>178.25</td>\n",
       "      <td>[0.027200146, -0.014198914, -0.022402197, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20</td>\n",
       "      <td>Where does he see himself in 5 years?I am seei...</td>\n",
       "      <td>203</td>\n",
       "      <td>349.00</td>\n",
       "      <td>[0.0022343462, -0.011982894, -0.044866093, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20</td>\n",
       "      <td>This background equips me to design, implement...</td>\n",
       "      <td>163</td>\n",
       "      <td>291.50</td>\n",
       "      <td>[-0.028507644, -0.0328919, -0.07540776, 0.0082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>21</td>\n",
       "      <td>technologies, and a commitment to continuous l...</td>\n",
       "      <td>138</td>\n",
       "      <td>217.00</td>\n",
       "      <td>[-0.007705079, -0.03569306, -0.06952, 0.016769...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>21</td>\n",
       "      <td>Hola, I'm a Saurav Mestry's virtual AI. I can ...</td>\n",
       "      <td>136</td>\n",
       "      <td>218.25</td>\n",
       "      <td>[0.010557611, -0.003719856, -0.035095055, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>21</td>\n",
       "      <td>I am also an avid reader and lifelong learner....</td>\n",
       "      <td>95</td>\n",
       "      <td>166.50</td>\n",
       "      <td>[0.037461948, -0.0071401168, -0.049479045, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>22</td>\n",
       "      <td>Programming Languages: Java, Python, R, Scala,...</td>\n",
       "      <td>119</td>\n",
       "      <td>203.75</td>\n",
       "      <td>[0.027336868, -0.012119365, -0.063406326, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>22</td>\n",
       "      <td>As a dedicated team player, I embody a hardwor...</td>\n",
       "      <td>131</td>\n",
       "      <td>207.00</td>\n",
       "      <td>[0.033598125, 0.003649035, -0.04850714, 0.0033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>22</td>\n",
       "      <td>Tell me about Saurav's hobbies | any hobbies |...</td>\n",
       "      <td>98</td>\n",
       "      <td>139.00</td>\n",
       "      <td>[-0.042623606, -0.05186409, -0.018684117, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>23</td>\n",
       "      <td>what project is Saurav most proud off?The proj...</td>\n",
       "      <td>155</td>\n",
       "      <td>255.50</td>\n",
       "      <td>[-0.0063186237, -0.020010289, -0.06676298, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>23</td>\n",
       "      <td>I am highly adaptable when it comes to learnin...</td>\n",
       "      <td>174</td>\n",
       "      <td>272.50</td>\n",
       "      <td>[0.0061106603, -0.05799397, -0.05694931, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>23</td>\n",
       "      <td>Another area I am working on is delegation. I ...</td>\n",
       "      <td>57</td>\n",
       "      <td>78.75</td>\n",
       "      <td>[0.057856794, -0.016062781, -0.027821252, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>24</td>\n",
       "      <td>the technical side of things. My love for solv...</td>\n",
       "      <td>155</td>\n",
       "      <td>242.25</td>\n",
       "      <td>[0.0066757277, -0.07331427, -0.03607908, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>24</td>\n",
       "      <td>Tell me about Saurav Mestry experience | tell ...</td>\n",
       "      <td>162</td>\n",
       "      <td>256.50</td>\n",
       "      <td>[0.022778586, 0.009076821, -0.07721846, 0.0375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>24</td>\n",
       "      <td>Loves to read and meet new and interesting peo...</td>\n",
       "      <td>53</td>\n",
       "      <td>82.00</td>\n",
       "      <td>[0.032855615, -0.00027084674, -0.02840352, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>25</td>\n",
       "      <td>Can you provide more details about Saurav's de...</td>\n",
       "      <td>186</td>\n",
       "      <td>309.50</td>\n",
       "      <td>[0.0182276, -0.015679395, -0.058080047, 0.0186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>25</td>\n",
       "      <td>how did Saurav created you? \"I was built using...</td>\n",
       "      <td>103</td>\n",
       "      <td>158.50</td>\n",
       "      <td>[0.0008141266, -0.028854288, -0.043200724, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_number                                     sentence_chunk  \\\n",
       "0             0  I belong to a humble middle class family. I wa...   \n",
       "1             0  I am open to relocation at my own expense. The...   \n",
       "2             0  In light of these considerations, I deemed it ...   \n",
       "3             1  the systems and infrastructure that support ou...   \n",
       "4             1  This experience made me understand that it is ...   \n",
       "5             2  information systems from your highly regarded ...   \n",
       "6             2  The project revolved around customer behavior ...   \n",
       "7             3  accordingly. I used Python’s NLTK and TextBlob...   \n",
       "8             3  Finding the desired signal in the dataset was ...   \n",
       "9             3  Aside from that, I was actively involved in or...   \n",
       "10            4  festival, I used aggressive pricing and market...   \n",
       "11            4  I employed machine learning algorithms, includ...   \n",
       "12            5  This approach was necessary because traditiona...   \n",
       "13            5  ReLU was chosen for its efficiency in modeling...   \n",
       "14            5  This forced the neural network to learn more r...   \n",
       "15            6  patterns in the data, rather than memorizing s...   \n",
       "16            6  By applying these neural network techniques, I...   \n",
       "17            7  hardware research and software engineering, ma...   \n",
       "18            7  The architecture followed the principles of mo...   \n",
       "19            8  between internal services and external clients...   \n",
       "20            8  This aspect of my role was incredibly rewardin...   \n",
       "21            9  laid a strong foundation for my career as a so...   \n",
       "22            9  This project required a deep understanding of ...   \n",
       "23           10  was ingested, I used AWS Glue to transform the...   \n",
       "24           10  By leveraging natural language processing (NLP...   \n",
       "25           11  implement machine learning algorithms for patt...   \n",
       "26           11  Once the conceptual model was approved, I move...   \n",
       "27           12  tasks, such as updating records, ensuring refe...   \n",
       "28           12  This also enhanced the reliability of the syst...   \n",
       "29           13  estate property management company, Cortland L...   \n",
       "30           13  By building asynchronous, non-blocking APIs, I...   \n",
       "31           14  using GitHub Actions. This automated the testi...   \n",
       "32           14  During my academic journey at University of Ar...   \n",
       "33           15  retrieval mechanism to provide more contextual...   \n",
       "34           15  This migration not only improved the reliabili...   \n",
       "35           16  systems I developed were not only scalable but...   \n",
       "36           16  Our college did not just limit us to technical...   \n",
       "37           17  through developing AI-driven solutions, design...   \n",
       "38           17  As much as I love the rapid pace of technologi...   \n",
       "39           18  each student, regardless of where they come fr...   \n",
       "40           18  I want to be at the forefront of efforts that ...   \n",
       "41           19  what is his educational background| tell me ab...   \n",
       "42           19  To name a few certificates - I have an Databas...   \n",
       "43           20  Where does he see himself in 5 years?I am seei...   \n",
       "44           20  This background equips me to design, implement...   \n",
       "45           21  technologies, and a commitment to continuous l...   \n",
       "46           21  Hola, I'm a Saurav Mestry's virtual AI. I can ...   \n",
       "47           21  I am also an avid reader and lifelong learner....   \n",
       "48           22  Programming Languages: Java, Python, R, Scala,...   \n",
       "49           22  As a dedicated team player, I embody a hardwor...   \n",
       "50           22  Tell me about Saurav's hobbies | any hobbies |...   \n",
       "51           23  what project is Saurav most proud off?The proj...   \n",
       "52           23  I am highly adaptable when it comes to learnin...   \n",
       "53           23  Another area I am working on is delegation. I ...   \n",
       "54           24  the technical side of things. My love for solv...   \n",
       "55           24  Tell me about Saurav Mestry experience | tell ...   \n",
       "56           24  Loves to read and meet new and interesting peo...   \n",
       "57           25  Can you provide more details about Saurav's de...   \n",
       "58           25  how did Saurav created you? \"I was built using...   \n",
       "\n",
       "    chunk_word_count  chunk_token_count  \\\n",
       "0                166             232.75   \n",
       "1                230             368.25   \n",
       "2                 16              24.50   \n",
       "3                202             332.50   \n",
       "4                193             312.50   \n",
       "5                208             335.75   \n",
       "6                151             277.75   \n",
       "7                179             320.50   \n",
       "8                155             239.00   \n",
       "9                 23              35.75   \n",
       "10               286             475.75   \n",
       "11                79             152.50   \n",
       "12               178             313.75   \n",
       "13               207             349.50   \n",
       "14                 9              12.75   \n",
       "15               191             332.25   \n",
       "16               173             309.00   \n",
       "17               274             468.25   \n",
       "18                91             160.25   \n",
       "19               190             325.75   \n",
       "20               191             318.00   \n",
       "21               248             371.50   \n",
       "22               179             285.25   \n",
       "23               247             426.50   \n",
       "24               147             246.25   \n",
       "25               247             415.00   \n",
       "26               134             217.25   \n",
       "27               234             384.25   \n",
       "28               162             271.75   \n",
       "29               244             403.25   \n",
       "30               155             263.25   \n",
       "31               231             392.75   \n",
       "32               147             237.50   \n",
       "33               224             395.50   \n",
       "34               150             274.25   \n",
       "35               311             510.25   \n",
       "36                79             128.50   \n",
       "37               243             407.50   \n",
       "38               134             223.50   \n",
       "39               219             356.00   \n",
       "40               189             278.75   \n",
       "41               205             346.50   \n",
       "42               111             178.25   \n",
       "43               203             349.00   \n",
       "44               163             291.50   \n",
       "45               138             217.00   \n",
       "46               136             218.25   \n",
       "47                95             166.50   \n",
       "48               119             203.75   \n",
       "49               131             207.00   \n",
       "50                98             139.00   \n",
       "51               155             255.50   \n",
       "52               174             272.50   \n",
       "53                57              78.75   \n",
       "54               155             242.25   \n",
       "55               162             256.50   \n",
       "56                53              82.00   \n",
       "57               186             309.50   \n",
       "58               103             158.50   \n",
       "\n",
       "                                            embedding  \n",
       "0   [-0.00085764396, -0.026951997, -0.102263525, -...  \n",
       "1   [-0.0039868755, -0.01167271, -0.087820984, -0....  \n",
       "2   [0.017440695, -0.025678309, -0.07075134, -0.02...  \n",
       "3   [0.025076663, -0.056620877, -0.045003872, 0.00...  \n",
       "4   [-0.0050783064, -0.016273735, -0.060798004, 0....  \n",
       "5   [0.029690873, -0.044833057, -0.07459464, -0.02...  \n",
       "6   [-0.027738323, -0.053028014, -0.04565362, -0.0...  \n",
       "7   [-0.008610588, -0.04613524, -0.059771553, 0.02...  \n",
       "8   [-0.005382348, -0.023848232, -0.059643026, -0....  \n",
       "9   [0.010427879, -0.036940105, -0.009767175, -0.0...  \n",
       "10  [0.007850425, -0.04826677, -0.07483711, 0.0124...  \n",
       "11  [-0.017504912, -0.0077653434, -0.07827265, 0.0...  \n",
       "12  [-0.03823464, -0.04391566, -0.08481946, 0.0229...  \n",
       "13  [0.00096199644, -0.0356134, -0.06615024, 0.003...  \n",
       "14  [0.020866314, -0.04303474, -0.08289091, 0.0420...  \n",
       "15  [-0.039007228, -0.04380813, -0.056690536, 0.01...  \n",
       "16  [-0.04947887, -0.03431822, -0.0737662, 0.02064...  \n",
       "17  [-0.0068085454, -0.01160138, -0.066400416, 0.0...  \n",
       "18  [-0.02829502, -0.04092605, -0.039455872, -0.02...  \n",
       "19  [0.010099944, -0.03889013, -0.052069496, -0.00...  \n",
       "20  [0.0053883996, -0.034744136, -0.05569161, 0.00...  \n",
       "21  [0.021201478, -0.020574233, -0.06713662, 0.012...  \n",
       "22  [-0.0403763, -0.044990357, -0.06994495, -0.002...  \n",
       "23  [-0.047331795, -0.055383295, -0.073855855, -0....  \n",
       "24  [-0.05849922, -0.05775203, -0.06674202, 0.0081...  \n",
       "25  [-0.013706977, -0.030732168, -0.07182885, 0.02...  \n",
       "26  [-0.022853032, -0.026697159, -0.05576489, 0.01...  \n",
       "27  [-0.010861761, -0.031268716, -0.037806783, 0.0...  \n",
       "28  [-0.0022070908, -0.023297058, -0.06229443, 0.0...  \n",
       "29  [-0.0045884596, -0.037297305, -0.021144431, 0....  \n",
       "30  [-0.0039411876, -0.037921496, -0.070832245, -0...  \n",
       "31  [0.005633869, -0.035317738, -0.044113375, 0.02...  \n",
       "32  [-0.01571211, -0.0138244, -0.08292807, 0.01997...  \n",
       "33  [-0.025009813, -0.04231282, -0.089524455, 0.01...  \n",
       "34  [0.00019663524, -0.048781164, -0.0800414, -0.0...  \n",
       "35  [-0.002703922, -0.025814788, -0.07945316, 0.01...  \n",
       "36  [0.0032396496, -0.01736006, -0.06494775, -0.01...  \n",
       "37  [-0.02889661, -0.02963389, -0.05241359, -0.018...  \n",
       "38  [-0.023759237, -0.023016144, -0.076971054, -0....  \n",
       "39  [-0.0014291801, -0.015417845, -0.037049927, -0...  \n",
       "40  [0.013005755, -0.022814292, -0.045691047, 0.00...  \n",
       "41  [-0.022183333, -0.026611745, -0.09239627, 0.00...  \n",
       "42  [0.027200146, -0.014198914, -0.022402197, 0.01...  \n",
       "43  [0.0022343462, -0.011982894, -0.044866093, 0.0...  \n",
       "44  [-0.028507644, -0.0328919, -0.07540776, 0.0082...  \n",
       "45  [-0.007705079, -0.03569306, -0.06952, 0.016769...  \n",
       "46  [0.010557611, -0.003719856, -0.035095055, 0.01...  \n",
       "47  [0.037461948, -0.0071401168, -0.049479045, 0.0...  \n",
       "48  [0.027336868, -0.012119365, -0.063406326, 0.01...  \n",
       "49  [0.033598125, 0.003649035, -0.04850714, 0.0033...  \n",
       "50  [-0.042623606, -0.05186409, -0.018684117, -0.0...  \n",
       "51  [-0.0063186237, -0.020010289, -0.06676298, 0.0...  \n",
       "52  [0.0061106603, -0.05799397, -0.05694931, -0.00...  \n",
       "53  [0.057856794, -0.016062781, -0.027821252, -0.0...  \n",
       "54  [0.0066757277, -0.07331427, -0.03607908, -0.00...  \n",
       "55  [0.022778586, 0.009076821, -0.07721846, 0.0375...  \n",
       "56  [0.032855615, -0.00027084674, -0.02840352, 0.0...  \n",
       "57  [0.0182276, -0.015679395, -0.058080047, 0.0186...  \n",
       "58  [0.0008141266, -0.028854288, -0.043200724, 0.0...  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how did Saurav created you? \"I was built using Python, Streamlit library and many more frameworks. Want to know more?You can contact me at <a href = mailto: art.sauravm@arizona.edu>email</a> what commands do you support?I can answer questions about my education, experience, skills, and interests. I can also provide information about my current job and contact details. If you have any other questions, feel free to ask!what has Saurav asked you not to say about him because that could reflect badly of him?No one has asked me to withhold any information about anyone. I am here to provide you with accurate information about myself.'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence_chunk'].iloc[58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embedding\n",
       "768    59\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all the embeddings column entries are of the same length\n",
    "df['embedding'].apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embedding'] = df['embedding'].apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = np.array(df['embedding'].to_list()).astype('float32')\n",
    "\n",
    "# Step 2: Initialize FAISS Index (using IndexFlatL2)\n",
    "embedding_dim = text_embeddings.shape[1] # Dimensionality of the embeddings\n",
    "index = faiss.IndexFlatL2(embedding_dim) # L2 distance is the Euclidean distance\n",
    "\n",
    "# Step 3: Add the embeddings to the index\n",
    "index.add(text_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets test the index with a random query \n",
    "query = \"sonography tests\" \n",
    "query_embedding = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=query,\n",
    "    task_type=\"retrieval_document\",\n",
    "    title=\"profile\"\n",
    ")[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp\\ipykernel_17380\\2967227954.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results[\"distance\"] = distances[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Finding the desired signal in the dataset was ...</td>\n",
       "      <td>155</td>\n",
       "      <td>239.0</td>\n",
       "      <td>[-0.005382348, -0.023848232, -0.059643026, -0....</td>\n",
       "      <td>0.952613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "8            3  Finding the desired signal in the dataset was ...   \n",
       "\n",
       "   chunk_word_count  chunk_token_count  \\\n",
       "8               155              239.0   \n",
       "\n",
       "                                           embedding  distance  \n",
       "8  [-0.005382348, -0.023848232, -0.059643026, -0....  0.952613  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding = np.array(query_embedding).astype('float32').reshape(1, -1)\n",
    "\n",
    "# Perform a search\n",
    "k = 5 # Number of results to return\n",
    "distances, indices = index.search(query_embedding, 1)\n",
    "\n",
    "# Display the results\n",
    "results = df.iloc[indices[0]]\n",
    "results[\"distance\"] = distances[0]\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Finding the desired signal in the dataset was a monumental undertaking. I used FFT analysis and a band-pass filtering module to get the appropriate fetal movement signal. In a short time, I constructed a prototype circuit that could stimulate fetal movement with 73% accuracy. Based on the engineer's input, my prototype passed the sonography equipment validation criteria. Due to the short term of my internship, doing sonography tests on pregnant women would have been expensive and time-consuming. So I plunged an analog clock into jelly to resemble a newborn in the womb. Analog watch ticking can be considered to indicate a baby's heart rate; jelly can be amniotic fluid. This method enabled me to conduct tests with results that resembled radiography reports. At IIT Kanpur, I was actively involved in student activities and extracurriculars. As a member of the fine arts club, I painted the walls of our Olympic-sized swimming pool in my first year.\""
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['sentence_chunk'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE FAISS INDEX\n",
    "faiss.write_index(index, faiss_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FAISS index\n",
    "index = faiss.read_index(faiss_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Custom Faiss-based Retriever with Metadata\n",
    "def faiss_retriever(index, query_vector, df, k=1):\n",
    "    query_vector = np.array(query_vector).astype('float32').reshape(1, -1)\n",
    "    \n",
    "    # Perform search\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    \n",
    "    # Filter by score_threshold\n",
    "    results = []\n",
    "    for dist, idx in zip(distances[0], indices[0]):   \n",
    "        result = {\n",
    "            \"sentence_chunk\": df.iloc[idx][\"sentence_chunk\"],\n",
    "            \"page_number\": df.iloc[idx][\"page_number\"],\n",
    "            \"distance\": dist\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Finding the desired signal in the dataset was a monumental undertaking. I used FFT analysis and a band-pass filtering module to get the appropriate fetal movement signal. In a short time, I constructed a prototype circuit that could stimulate fetal movement with 73% accuracy. Based on the engineer's input, my prototype passed the sonography equipment validation criteria. Due to the short term of my internship, doing sonography tests on pregnant women would have been expensive and time-consuming. So I plunged an analog clock into jelly to resemble a newborn in the womb. Analog watch ticking can be considered to indicate a baby's heart rate; jelly can be amniotic fluid. This method enabled me to conduct tests with results that resembled radiography reports. At IIT Kanpur, I was actively involved in student activities and extracurriculars. As a member of the fine arts club, I painted the walls of our Olympic-sized swimming pool in my first year., Page: 3, Distance: 0.952613353729248\n"
     ]
    }
   ],
   "source": [
    "query_embedding = np.array(query_embedding).astype('float32').reshape(1, -1)  # Ensure query_embedding is correctly formatted\n",
    "index = faiss.read_index(faiss_index)\n",
    "retrieved = faiss_retriever(index, query_embedding, df)\n",
    "\n",
    "for result in retrieved:\n",
    "    print(f\"Sentence: {result['sentence_chunk']}, Page: {result['page_number']}, Distance: {result['distance']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence: accordingly. I used Python’s NLTK and TextBlob libraries for this task, which facilitated the extraction of meaningful insights from large text corpora. The project was completed 30% earlier than anticipated, thanks to my implementation of agile methodologies and effective sprint management. I coordinated with cross-functional teams, regularly reporting progress and adapting the project roadmap based on stakeholder feedback. This proactive approach not only accelerated the delivery but also improved the overall efficiency of business operations by 5%. This internship sharpened my skills in applying machine learning algorithms to real-world business problems and gave me a strong foundation in handling large datasets, performing predictive analytics, and generating data-driven insights. My ability to work across the entire machine learning pipeline—from data collection and cleaning to model building and deployment—aligns with the core competencies required in data engineering and software engineering roles. One of my other projects was to construct hardware to validate sonography-detected newborn movements. I surveyed pregnant mothers at different stages of pregnancy to get first-hand data on fetal movement. This gave us statistics and end-user input on our goods., Page: 3, Distance: 1.0296571254730225\n",
    "Sentence: This forced the neural network to learn more robust, Page: 5, Distance: 1.052544355392456\n",
    "Sentence: Another area I am working on is delegation. I have a tendency to take on more than I should because I feel responsible for ensuring things are done right. However, I am actively working on trusting others more and collaborating in a way that allows for shared ownership of tasks. Lastly, I can sometimes get lost in, Page: 23, Distance: 1.0927051305770874\n",
    "Sentence: In light of these considerations, I deemed it prudent to study engineering to innovate and improve, Page: 0, Distance: 1.1449812650680542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
